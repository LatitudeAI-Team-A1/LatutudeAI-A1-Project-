{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3185696,"status":"ok","timestamp":1764134440731,"user":{"displayName":"Joseph Boadi","userId":"06232502213247757960"},"user_tz":300},"id":"7y43-nu1YF3T","outputId":"7d39f372-3ee1-4dfb-c86b-9de3dd6234f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","\n","ğŸš€ Processing train...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7000/7000 [39:15<00:00,  2.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","ğŸš€ Processing val...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [06:03<00:00,  2.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","ğŸ“¦ Zipping...\n","âœ… DONE.\n"]}],"source":["# ==============================================================================\n","# CELL 1: SIMPLE DATA PREPARATION\n","# ==============================================================================\n","import os\n","import shutil\n","import torch\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","from scipy.ndimage import label as cc_label\n","from google.colab import drive\n","\n","# 1. MOUNT\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive', force_remount=True)\n","\n","# 2. PATHS\n","DRIVE_DATA = \"/content/drive/MyDrive/Latitude_AI_Team/data\"\n","LOCAL_DATA = \"/content/data\"\n","\n","# Clear local disk\n","if os.path.exists(LOCAL_DATA): shutil.rmtree(LOCAL_DATA)\n","\n","# Create directories\n","PT_DIR = os.path.join(LOCAL_DATA, \"precomputed_masks\")\n","IMG_DIR = os.path.join(LOCAL_DATA, \"images\")\n","os.makedirs(PT_DIR, exist_ok=True)\n","os.makedirs(os.path.join(IMG_DIR, \"train\"), exist_ok=True)\n","os.makedirs(os.path.join(IMG_DIR, \"val\"), exist_ok=True)\n","\n","# Config\n","BDD_IDS = [6, 7, 11, 13, 12, 14, 15, 17, 18]\n","ID_TO_LABEL = {bdd_id: i+1 for i, bdd_id in enumerate(BDD_IDS)}\n","\n","# 3. PROCESSING FUNCTION\n","def process_split(mask_folder, img_folder, split_name):\n","    print(f\"\\n Processing {split_name}...\")\n","    mask_source = os.path.join(DRIVE_DATA, mask_folder)\n","    img_source = os.path.join(DRIVE_DATA, img_folder)\n","\n","    files = [f for f in os.listdir(mask_source) if f.endswith('.png')]\n","\n","    for f in tqdm(files):\n","        try:\n","            basename = f.replace(\"_train_id.png\", \"\")\n","\n","            # Load Mask\n","            mask = np.array(Image.open(os.path.join(mask_source, f)).convert(\"L\"), dtype=np.int32)\n","\n","            boxes, labels, masks = [], [], []\n","\n","            # Extract Instances\n","            for bdd_id in BDD_IDS:\n","                class_mask = (mask == bdd_id).astype(np.uint8)\n","                if class_mask.sum() < 10: continue\n","\n","                inst_map, ninst = cc_label(class_mask)\n","                for i in range(1, ninst+1):\n","                    pos = np.where(inst_map == i)\n","                    ymin, xmin, ymax, xmax = np.min(pos[0]), np.min(pos[1]), np.max(pos[0]), np.max(pos[1])\n","                    if (ymax-ymin) < 5 or (xmax-xmin) < 5: continue\n","\n","                    boxes.append([xmin, ymin, xmax, ymax])\n","                    labels.append(ID_TO_LABEL[bdd_id])\n","                    masks.append((inst_map == i).astype(np.uint8))\n","\n","            if not boxes: continue\n","\n","            # Save PT\n","            torch.save({\n","                \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n","                \"labels\": torch.tensor(labels, dtype=torch.int64),\n","                \"masks\": torch.tensor(np.array(masks), dtype=torch.uint8)\n","            }, os.path.join(PT_DIR, basename + \".pt\"))\n","\n","            # Copy Image\n","            src_img = os.path.join(img_source, basename + \".jpg\")\n","            dst_img = os.path.join(IMG_DIR, split_name, basename + \".jpg\")\n","            if os.path.exists(src_img): shutil.copy(src_img, dst_img)\n","\n","        except: pass\n","\n","# 4. EXECUTE\n","# Train Set\n","process_split(\n","    \"bdd100k_segmentations/bdd100k_seg_maps_2/labels/train\",\n","    \"bdd100k_images_10k/10k/train\",\n","    \"train\"\n",")\n","\n","# Validation Set\n","process_split(\n","    \"bdd100k_segmentations/bdd100k_seg_maps_2/labels/val\",\n","    \"bdd100k_images_10k/10k/val\",\n","    \"val\"\n",")\n","\n","# 5. BACKUP\n","print(\"\\nğŸ“¦ Zipping...\")\n","shutil.make_archive(\"/content/bdd_cache\", 'zip', LOCAL_DATA)\n","shutil.move(\"/content/bdd_cache.zip\", os.path.join(DRIVE_DATA, \"bdd100k_fast_cache.zip\"))\n","print(\"âœ… DONE.\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"bP_78JZ9aNr9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1764202646471,"user_tz":300,"elapsed":66958351,"user":{"displayName":"Joseph Boadi","userId":"06232502213247757960"}},"outputId":"cddf112d-c0dc-4184-b84c-87e6c886313d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ Training on: cuda\n","ğŸ“Š Dataset: 6945 Training | 988 Validation\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20251126_054132-wcialmeg</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/latitude-ai/latitude-ai-maskrcnn/runs/wcialmeg' target=\"_blank\">FULL-PRODUCTION-RUN</a></strong> to <a href='https://wandb.ai/latitude-ai/latitude-ai-maskrcnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/latitude-ai/latitude-ai-maskrcnn' target=\"_blank\">https://wandb.ai/latitude-ai/latitude-ai-maskrcnn</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/latitude-ai/latitude-ai-maskrcnn/runs/wcialmeg' target=\"_blank\">https://wandb.ai/latitude-ai/latitude-ai-maskrcnn/runs/wcialmeg</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸš€ Starting Full Training Loop (25 Epochs)...\n","\n","============================================================\n","âœ… EPOCH 1/25 COMPLETE | Time: 39.7 min\n","============================================================\n","ğŸ“‰ Total Loss: 1.1373\n","   â€¢ Mask Loss:       0.2561\n","   â€¢ Box Reg Loss:    0.3114\n","   â€¢ Classifier Loss: 0.2665\n","   â€¢ Objectness Loss: 0.1034\n","   â€¢ RPN Box Loss:    0.2000\n","â³ Validating Epoch 1...\n","ğŸ“ˆ Validation AP: 0.1814 (Best: 0.0000)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.1814) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 2/25 COMPLETE | Time: 39.8 min\n","============================================================\n","ğŸ“‰ Total Loss: 1.0376\n","   â€¢ Mask Loss:       0.2398\n","   â€¢ Box Reg Loss:    0.2909\n","   â€¢ Classifier Loss: 0.2378\n","   â€¢ Objectness Loss: 0.0840\n","   â€¢ RPN Box Loss:    0.1851\n","â³ Validating Epoch 2...\n","ğŸ“ˆ Validation AP: 0.2012 (Best: 0.1814)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.2012) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 3/25 COMPLETE | Time: 39.8 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.9912\n","   â€¢ Mask Loss:       0.2329\n","   â€¢ Box Reg Loss:    0.2818\n","   â€¢ Classifier Loss: 0.2260\n","   â€¢ Objectness Loss: 0.0737\n","   â€¢ RPN Box Loss:    0.1768\n","â³ Validating Epoch 3...\n","ğŸ“ˆ Validation AP: 0.2176 (Best: 0.2012)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.2176) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 4/25 COMPLETE | Time: 39.9 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.9523\n","   â€¢ Mask Loss:       0.2270\n","   â€¢ Box Reg Loss:    0.2745\n","   â€¢ Classifier Loss: 0.2157\n","   â€¢ Objectness Loss: 0.0658\n","   â€¢ RPN Box Loss:    0.1693\n","â³ Validating Epoch 4...\n","ğŸ“ˆ Validation AP: 0.2308 (Best: 0.2176)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.2308) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 5/25 COMPLETE | Time: 39.9 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.9223\n","   â€¢ Mask Loss:       0.2251\n","   â€¢ Box Reg Loss:    0.2682\n","   â€¢ Classifier Loss: 0.2069\n","   â€¢ Objectness Loss: 0.0595\n","   â€¢ RPN Box Loss:    0.1625\n","â³ Validating Epoch 5...\n","ğŸ“ˆ Validation AP: 0.2296 (Best: 0.2308)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 6/25 COMPLETE | Time: 40.0 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.8891\n","   â€¢ Mask Loss:       0.2199\n","   â€¢ Box Reg Loss:    0.2604\n","   â€¢ Classifier Loss: 0.1972\n","   â€¢ Objectness Loss: 0.0547\n","   â€¢ RPN Box Loss:    0.1570\n","â³ Validating Epoch 6...\n","ğŸ“ˆ Validation AP: 0.2340 (Best: 0.2308)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.2340) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 7/25 COMPLETE | Time: 40.0 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.8686\n","   â€¢ Mask Loss:       0.2187\n","   â€¢ Box Reg Loss:    0.2572\n","   â€¢ Classifier Loss: 0.1913\n","   â€¢ Objectness Loss: 0.0500\n","   â€¢ RPN Box Loss:    0.1513\n","â³ Validating Epoch 7...\n","ğŸ“ˆ Validation AP: 0.2547 (Best: 0.2340)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.2547) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 8/25 COMPLETE | Time: 40.1 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.8484\n","   â€¢ Mask Loss:       0.2149\n","   â€¢ Box Reg Loss:    0.2536\n","   â€¢ Classifier Loss: 0.1854\n","   â€¢ Objectness Loss: 0.0475\n","   â€¢ RPN Box Loss:    0.1468\n","â³ Validating Epoch 8...\n","ğŸ“ˆ Validation AP: 0.2567 (Best: 0.2547)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.2567) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 9/25 COMPLETE | Time: 40.1 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.8247\n","   â€¢ Mask Loss:       0.2117\n","   â€¢ Box Reg Loss:    0.2485\n","   â€¢ Classifier Loss: 0.1800\n","   â€¢ Objectness Loss: 0.0433\n","   â€¢ RPN Box Loss:    0.1413\n","â³ Validating Epoch 9...\n","ğŸ“ˆ Validation AP: 0.2491 (Best: 0.2567)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 10/25 COMPLETE | Time: 40.2 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.8065\n","   â€¢ Mask Loss:       0.2098\n","   â€¢ Box Reg Loss:    0.2449\n","   â€¢ Classifier Loss: 0.1738\n","   â€¢ Objectness Loss: 0.0405\n","   â€¢ RPN Box Loss:    0.1375\n","â³ Validating Epoch 10...\n","ğŸ“ˆ Validation AP: 0.2498 (Best: 0.2567)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 11/25 COMPLETE | Time: 40.2 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.7887\n","   â€¢ Mask Loss:       0.2074\n","   â€¢ Box Reg Loss:    0.2419\n","   â€¢ Classifier Loss: 0.1687\n","   â€¢ Objectness Loss: 0.0375\n","   â€¢ RPN Box Loss:    0.1332\n","â³ Validating Epoch 11...\n","ğŸ“ˆ Validation AP: 0.2479 (Best: 0.2567)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 12/25 COMPLETE | Time: 40.2 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.7706\n","   â€¢ Mask Loss:       0.2066\n","   â€¢ Box Reg Loss:    0.2366\n","   â€¢ Classifier Loss: 0.1617\n","   â€¢ Objectness Loss: 0.0361\n","   â€¢ RPN Box Loss:    0.1296\n","â³ Validating Epoch 12...\n","ğŸ“ˆ Validation AP: 0.2475 (Best: 0.2567)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 13/25 COMPLETE | Time: 40.4 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.6864\n","   â€¢ Mask Loss:       0.1957\n","   â€¢ Box Reg Loss:    0.2142\n","   â€¢ Classifier Loss: 0.1378\n","   â€¢ Objectness Loss: 0.0266\n","   â€¢ RPN Box Loss:    0.1122\n","â³ Validating Epoch 13...\n","ğŸ“ˆ Validation AP: 0.2698 (Best: 0.2567)\n","============================================================\n","\n","   -> ğŸ’¾ Saved NEW BEST Checkpoint (AP 0.2698) to Drive\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 14/25 COMPLETE | Time: 40.4 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.6500\n","   â€¢ Mask Loss:       0.1917\n","   â€¢ Box Reg Loss:    0.2036\n","   â€¢ Classifier Loss: 0.1264\n","   â€¢ Objectness Loss: 0.0231\n","   â€¢ RPN Box Loss:    0.1051\n","â³ Validating Epoch 14...\n","ğŸ“ˆ Validation AP: 0.2655 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 15/25 COMPLETE | Time: 40.5 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.6344\n","   â€¢ Mask Loss:       0.1901\n","   â€¢ Box Reg Loss:    0.1992\n","   â€¢ Classifier Loss: 0.1224\n","   â€¢ Objectness Loss: 0.0212\n","   â€¢ RPN Box Loss:    0.1015\n","â³ Validating Epoch 15...\n","ğŸ“ˆ Validation AP: 0.2644 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 16/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.6168\n","   â€¢ Mask Loss:       0.1884\n","   â€¢ Box Reg Loss:    0.1934\n","   â€¢ Classifier Loss: 0.1170\n","   â€¢ Objectness Loss: 0.0196\n","   â€¢ RPN Box Loss:    0.0985\n","â³ Validating Epoch 16...\n","ğŸ“ˆ Validation AP: 0.2652 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 17/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.6020\n","   â€¢ Mask Loss:       0.1866\n","   â€¢ Box Reg Loss:    0.1887\n","   â€¢ Classifier Loss: 0.1126\n","   â€¢ Objectness Loss: 0.0183\n","   â€¢ RPN Box Loss:    0.0957\n","â³ Validating Epoch 17...\n","ğŸ“ˆ Validation AP: 0.2612 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 18/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5824\n","   â€¢ Mask Loss:       0.1845\n","   â€¢ Box Reg Loss:    0.1825\n","   â€¢ Classifier Loss: 0.1070\n","   â€¢ Objectness Loss: 0.0168\n","   â€¢ RPN Box Loss:    0.0917\n","â³ Validating Epoch 18...\n","ğŸ“ˆ Validation AP: 0.2605 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 19/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5805\n","   â€¢ Mask Loss:       0.1842\n","   â€¢ Box Reg Loss:    0.1813\n","   â€¢ Classifier Loss: 0.1066\n","   â€¢ Objectness Loss: 0.0165\n","   â€¢ RPN Box Loss:    0.0918\n","â³ Validating Epoch 19...\n","ğŸ“ˆ Validation AP: 0.2575 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 20/25 COMPLETE | Time: 40.7 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5774\n","   â€¢ Mask Loss:       0.1838\n","   â€¢ Box Reg Loss:    0.1804\n","   â€¢ Classifier Loss: 0.1058\n","   â€¢ Objectness Loss: 0.0166\n","   â€¢ RPN Box Loss:    0.0909\n","â³ Validating Epoch 20...\n","ğŸ“ˆ Validation AP: 0.2581 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 21/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5757\n","   â€¢ Mask Loss:       0.1838\n","   â€¢ Box Reg Loss:    0.1801\n","   â€¢ Classifier Loss: 0.1049\n","   â€¢ Objectness Loss: 0.0163\n","   â€¢ RPN Box Loss:    0.0907\n","â³ Validating Epoch 21...\n","ğŸ“ˆ Validation AP: 0.2585 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 22/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5750\n","   â€¢ Mask Loss:       0.1839\n","   â€¢ Box Reg Loss:    0.1797\n","   â€¢ Classifier Loss: 0.1048\n","   â€¢ Objectness Loss: 0.0164\n","   â€¢ RPN Box Loss:    0.0902\n","â³ Validating Epoch 22...\n","ğŸ“ˆ Validation AP: 0.2576 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 23/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5737\n","   â€¢ Mask Loss:       0.1839\n","   â€¢ Box Reg Loss:    0.1793\n","   â€¢ Classifier Loss: 0.1041\n","   â€¢ Objectness Loss: 0.0161\n","   â€¢ RPN Box Loss:    0.0902\n","â³ Validating Epoch 23...\n","ğŸ“ˆ Validation AP: 0.2570 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 24/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5741\n","   â€¢ Mask Loss:       0.1837\n","   â€¢ Box Reg Loss:    0.1793\n","   â€¢ Classifier Loss: 0.1047\n","   â€¢ Objectness Loss: 0.0161\n","   â€¢ RPN Box Loss:    0.0903\n","â³ Validating Epoch 24...\n","ğŸ“ˆ Validation AP: 0.2571 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n","\n","============================================================\n","âœ… EPOCH 25/25 COMPLETE | Time: 40.6 min\n","============================================================\n","ğŸ“‰ Total Loss: 0.5738\n","   â€¢ Mask Loss:       0.1836\n","   â€¢ Box Reg Loss:    0.1792\n","   â€¢ Classifier Loss: 0.1046\n","   â€¢ Objectness Loss: 0.0163\n","   â€¢ RPN Box Loss:    0.0900\n","â³ Validating Epoch 25...\n","ğŸ“ˆ Validation AP: 0.2574 (Best: 0.2698)\n","============================================================\n","\n","   -> ğŸ›¡ï¸ Saved Safety Backup to Drive\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/loss_box_reg</td><td>â–ˆâ–„â–…â–‡â–„â–„â–‡â–†â–„â–†â–†â–…â–‡â–ƒâ–†â–†â–„â–„â–ƒâ–…â–ƒâ–…â–ˆâ–ƒâ–†â–‚â–„â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–‚â–„â–„â–â–…â–„â–‚</td></tr><tr><td>train/loss_classifier</td><td>â–‡â–‚â–„â–‡â–…â–ƒâ–ˆâ–†â–…â–‡â–…â–†â–„â–„â–„â–‚â–„â–†â–ƒâ–ƒâ–‡â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–„â–‚â–‚â–‚â–…â–ƒâ–‚â–‚â–â–‚â–‚â–ƒ</td></tr><tr><td>train/loss_mask</td><td>â–„â–„â–ƒâ–…â–…â–ƒâ–‚â–„â–„â–ƒâ–‚â–ƒâ–„â–…â–…â–„â–â–„â–ˆâ–†â–…â–‚â–„â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–„â–ƒâ–â–ƒâ–„</td></tr><tr><td>train/loss_objectness</td><td>â–ˆâ–ƒâ–†â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/loss_rpn_box_reg</td><td>â–‚â–ˆâ–…â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–„â–ƒâ–â–„â–„â–„â–‚â–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–„â–â–…â–ƒâ–‚â–â–â–‚â–„â–â–‚â–â–‚</td></tr><tr><td>train/total_loss</td><td>â–‡â–‡â–ƒâ–ˆâ–„â–…â–ƒâ–„â–…â–„â–ƒâ–…â–„â–„â–…â–…â–„â–‡â–ƒâ–‚â–†â–â–„â–‚â–‚â–‚â–ƒâ–„â–‚â–„â–â–ƒâ–…â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–</td></tr><tr><td>val/mAP_iou_50</td><td>â–â–ƒâ–„â–…â–…â–…â–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>86825</td></tr><tr><td>train/loss_box_reg</td><td>0.16783</td></tr><tr><td>train/loss_classifier</td><td>0.12329</td></tr><tr><td>train/loss_mask</td><td>0.21208</td></tr><tr><td>train/loss_objectness</td><td>0.02687</td></tr><tr><td>train/loss_rpn_box_reg</td><td>0.04609</td></tr><tr><td>train/total_loss</td><td>0.57617</td></tr><tr><td>val/mAP_iou_50</td><td>0.45126</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">FULL-PRODUCTION-RUN</strong> at: <a href='https://wandb.ai/latitude-ai/latitude-ai-maskrcnn/runs/wcialmeg' target=\"_blank\">https://wandb.ai/latitude-ai/latitude-ai-maskrcnn/runs/wcialmeg</a><br> View project at: <a href='https://wandb.ai/latitude-ai/latitude-ai-maskrcnn' target=\"_blank\">https://wandb.ai/latitude-ai/latitude-ai-maskrcnn</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20251126_054132-wcialmeg/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ‰ Full Training Pipeline Completed Successfully.\n"]}],"source":["# ==============================================================================\n","# CELL 2: FULL PRODUCTION TRAINING RUN (25 EPOCHS)\n","\n","!pip install torchmetrics wandb -q\n","\n","# IMPORTS\n","import os\n","import shutil\n","import time\n","import random\n","import torch\n","import wandb\n","import torchvision\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as F\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","from torchmetrics.detection import MeanAveragePrecision\n","from torch.cuda import empty_cache\n","\n","wandb.login()\n","\n","# CONFIGURATION\n","\n","DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(f\"ğŸš€ Training on: {DEVICE}\")\n","\n","NUM_WORKERS = 2         # Fast I/O for local data\n","PIN_MEMORY = True\n","\n","# Training Settings\n","BATCH_SIZE = 2\n","EPOCHS = 25\n","LEARNING_RATE = 1e-4\n","WEIGHT_DECAY = 0.0005\n","\n","# Local Data Paths\n","DATA_ROOT = \"/content/data\"\n","PT_DIR = os.path.join(DATA_ROOT, \"precomputed_masks\")\n","TRAIN_IMG_DIR = os.path.join(DATA_ROOT, \"images/train\")\n","VAL_IMG_DIR = os.path.join(DATA_ROOT, \"images/val\")\n","\n","# Persistence Paths (Google Drive)\n","DRIVE_MODELS_DIR = \"/content/drive/MyDrive/Latitude_AI_Team/models\"\n","os.makedirs(DRIVE_MODELS_DIR, exist_ok=True)\n","\n","CHECKPOINT_FILENAME = \"best_model_checkpoint_full_run.pth\"\n","LATEST_FILENAME = \"latest_model_checkpoint.pth\"\n","\n","# Full Paths\n","DRIVE_CHECKPOINT_PATH = os.path.join(DRIVE_MODELS_DIR, CHECKPOINT_FILENAME)\n","DRIVE_LATEST_PATH = os.path.join(DRIVE_MODELS_DIR, LATEST_FILENAME)\n","LOCAL_CHECKPOINT_PATH = CHECKPOINT_FILENAME\n","LOCAL_LATEST_PATH = LATEST_FILENAME\n","\n","# DATA INTEGRITY CHECK\n","if not os.path.exists(PT_DIR) or len(os.listdir(PT_DIR)) == 0:\n","    raise FileNotFoundError(f\"CRITICAL: Local data missing at {PT_DIR}\")\n","\n","# 4. DATASET CLASS\n","class BDDPrecomputedDataset(Dataset):\n","    def __init__(self, img_dir, pt_dir, basenames, transforms=None, train_mode=False):\n","        self.img_dir = img_dir\n","        self.pt_dir = pt_dir\n","        self.basenames = basenames\n","        self.transforms = transforms\n","        self.train_mode = train_mode\n","        self.color_jitter = T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05)\n","\n","    def __len__(self): return len(self.basenames)\n","\n","    def __getitem__(self, idx):\n","        basename = self.basenames[idx]\n","\n","        # Load Image (Fast from local SSD)\n","        img_path = os.path.join(self.img_dir, basename + \".jpg\")\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        # Load Tensors\n","        data = torch.load(os.path.join(self.pt_dir, basename + \".pt\"))\n","\n","        boxes = data[\"boxes\"]\n","        labels = data[\"labels\"]\n","        masks = data[\"masks\"]\n","\n","        # Augmentation\n","        if self.train_mode:\n","            if random.random() < 0.5: img = self.color_jitter(img)\n","            if random.random() < 0.5:\n","                img = F.hflip(img)\n","                masks = F.hflip(masks)\n","                W_img, _ = img.size\n","                boxes[:, [0, 2]] = W_img - boxes[:, [2, 0]]\n","\n","        target = {\"boxes\": boxes, \"labels\": labels, \"masks\": masks, \"image_id\": torch.tensor([idx], dtype=torch.int64)}\n","        img_tensor = T.ToTensor()(img)\n","        return img_tensor, target\n","\n","def collate_fn(batch): return tuple(zip(*batch))\n","\n","\n","# Scan local folder to define splits based on actual files present\n","all_pt = set(f.replace('.pt', '') for f in os.listdir(PT_DIR) if f.endswith('.pt'))\n","train_imgs = set(f.replace('.jpg', '') for f in os.listdir(TRAIN_IMG_DIR))\n","val_imgs = set(f.replace('.jpg', '') for f in os.listdir(VAL_IMG_DIR))\n","\n","# Intersect to ensure we only load valid pairs\n","train_basenames = sorted(list(all_pt.intersection(train_imgs)))\n","val_basenames = sorted(list(all_pt.intersection(val_imgs)))\n","\n","TRAIN_SIZE = len(train_basenames)\n","VAL_SIZE = len(val_basenames)\n","\n","print(f\" Dataset: {TRAIN_SIZE} Training | {VAL_SIZE} Validation\")\n","\n","train_loader = DataLoader(\n","    BDDPrecomputedDataset(TRAIN_IMG_DIR, PT_DIR, train_basenames, train_mode=True),\n","    batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, collate_fn=collate_fn, pin_memory=PIN_MEMORY\n",")\n","val_loader = DataLoader(\n","    BDDPrecomputedDataset(VAL_IMG_DIR, PT_DIR, val_basenames, train_mode=False),\n","    batch_size=1, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_fn, pin_memory=PIN_MEMORY\n",")\n","\n","# METRICS\n","def calculate_ap_metrics(model, val_loader, device, epoch):\n","    model.eval()\n","    # Use 'segm' for the full quality check on masks\n","    metric = MeanAveragePrecision(box_format=\"xyxy\", iou_type=\"segm\").to(device)\n","\n","    with torch.no_grad():\n","        for i, (images, targets) in enumerate(val_loader):\n","            images = [img.to(device) for img in images]\n","            outputs = model(images)\n","            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","            processed = []\n","            for pred in outputs:\n","                if 'masks' in pred:\n","                    # Convert float masks to uint8\n","                    pred['masks'] = (pred['masks'] > 0.5).squeeze(1).to(torch.uint8)\n","                processed.append(pred)\n","            metric.update(processed, targets)\n","\n","    res = metric.compute()\n","    mAP_all = res['map'].item(); mAP_50 = res['map_50'].item(); mAP_75 = res['map_75'].item()\n","\n","    wandb.log({\n","        \"val/mAP_iou_all\": mAP_all,\n","        \"val/mAP_iou_50\": mAP_50,\n","        \"val/mAP_iou_75\": mAP_75,\n","        \"val/mAP_small\": res['map_small'].item(),\n","        \"epoch\": epoch\n","    })\n","    model.train(); empty_cache()\n","    return mAP_all\n","\n","# MODEL & OPTIMIZER\n","BDD_IDS = [6, 7, 11, 13, 12, 14, 15, 17, 18]; NUM_CLASSES = 1 + len(BDD_IDS)\n","\n","def get_model(num_classes):\n","    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n","    return model\n","\n","model = get_model(NUM_CLASSES).to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n","\n","# RESUMPTION (From Drive)\n","start_epoch = 1; best_avg_ap = 0.0\n","\n","# Check Drive for checkpoints (since local is fresh)\n","if os.path.exists(DRIVE_LATEST_PATH):\n","    print(f\" Found LATEST checkpoint on Drive. Copying...\")\n","    shutil.copy(DRIVE_LATEST_PATH, LOCAL_LATEST_PATH)\n","    ckpt = torch.load(LOCAL_LATEST_PATH)\n","    model.load_state_dict(ckpt['model_state_dict'])\n","    optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n","    start_epoch = ckpt['epoch'] + 1\n","    best_avg_ap = ckpt.get('mAP', 0.0)\n","    print(f\" Resuming from Epoch {start_epoch}. Best AP: {best_avg_ap:.4f}\")\n","elif os.path.exists(DRIVE_CHECKPOINT_PATH):\n","    print(f\" Found BEST checkpoint on Drive. Copying...\")\n","    shutil.copy(DRIVE_CHECKPOINT_PATH, LOCAL_CHECKPOINT_PATH)\n","    ckpt = torch.load(LOCAL_CHECKPOINT_PATH)\n","    model.load_state_dict(ckpt['model_state_dict'])\n","    optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n","    start_epoch = ckpt['epoch'] + 1\n","    best_avg_ap = ckpt.get('mAP', 0.0)\n","    print(f\"Resuming from Epoch {start_epoch} (Best Model).\")\n","\n","wandb.init(project=\"latitude-ai-maskrcnn\", name=\"FULL-PRODUCTION-RUN\", config={\n","    \"epochs\": EPOCHS, \"train_size\": TRAIN_SIZE, \"val_size\": VAL_SIZE, \"lr\": LEARNING_RATE\n","})\n","\n","# TRAINING LOOP\n","print(f\" Starting Full Training Loop ({EPOCHS} Epochs)...\")\n","global_step = 0\n","model.train()\n","\n","for epoch in range(start_epoch, EPOCHS + 1):\n","    epoch_loss = 0.0\n","    start = time.time()\n","\n","    # Track detailed loss components\n","    running_losses = {\"mask\": 0, \"box\": 0, \"class\": 0, \"obj\": 0, \"rpn_box\": 0}\n","\n","    for i, (images, targets) in enumerate(train_loader):\n","        images = [img.to(DEVICE) for img in images]\n","        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        total_loss = sum(loss for loss in loss_dict.values())\n","\n","        optimizer.zero_grad(); total_loss.backward(); optimizer.step()\n","        epoch_loss += total_loss.item(); global_step += 1\n","\n","        # Accumulate components\n","        running_losses[\"mask\"] += loss_dict['loss_mask'].item()\n","        running_losses[\"box\"] += loss_dict['loss_box_reg'].item()\n","        running_losses[\"class\"] += loss_dict['loss_classifier'].item()\n","        running_losses[\"obj\"] += loss_dict['loss_objectness'].item()\n","        running_losses[\"rpn_box\"] += loss_dict['loss_rpn_box_reg'].item()\n","\n","        # Log all 5 Losses\n","        wandb.log({\n","            \"train/total_loss\": total_loss.item(),\n","            \"train/loss_mask\": loss_dict['loss_mask'].item(),\n","            \"train/loss_box_reg\": loss_dict['loss_box_reg'].item(),\n","            \"train/loss_classifier\": loss_dict['loss_classifier'].item(),\n","            \"train/loss_objectness\": loss_dict['loss_objectness'].item(),\n","            \"train/loss_rpn_box_reg\": loss_dict['loss_rpn_box_reg'].item(),\n","            \"epoch\": epoch, \"step\": global_step, \"lr\": optimizer.param_groups[0]['lr']\n","        })\n","\n","    avg_loss = epoch_loss / len(train_loader)\n","    num_batches = len(train_loader)\n","\n","    # Print Average Components\n","    print(f\"\\n{'='*60}\")\n","    print(f\"EPOCH {epoch}/{EPOCHS} COMPLETE | Time: {(time.time()-start)/60:.1f} min\")\n","    print(f\"{'='*60}\")\n","    print(f\"ğŸ“‰ Total Loss: {avg_loss:.4f}\")\n","    print(f\"   â€¢ Mask Loss:       {running_losses['mask']/num_batches:.4f}\")\n","    print(f\"   â€¢ Box Reg Loss:    {running_losses['box']/num_batches:.4f}\")\n","    print(f\"   â€¢ Classifier Loss: {running_losses['class']/num_batches:.4f}\")\n","    print(f\"   â€¢ Objectness Loss: {running_losses['obj']/num_batches:.4f}\")\n","    print(f\"   â€¢ RPN Box Loss:    {running_losses['rpn_box']/num_batches:.4f}\")\n","\n","    print(f\" Validating Epoch {epoch}...\")\n","    ap = calculate_ap_metrics(model, val_loader, DEVICE, epoch)\n","    lr_scheduler.step(ap)\n","\n","    print(f\" Validation AP: {ap:.4f} (Best: {best_avg_ap:.4f})\")\n","    print(f\"{'='*60}\\n\")\n","\n","    if ap > best_avg_ap:\n","        best_avg_ap = ap\n","        torch.save({\n","            'epoch': epoch, 'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(), 'mAP': best_avg_ap\n","        }, LOCAL_CHECKPOINT_PATH)\n","        shutil.copy(LOCAL_CHECKPOINT_PATH, DRIVE_CHECKPOINT_PATH) # Sync to Drive\n","        print(f\"   ->  Saved NEW BEST Checkpoint (AP {ap:.4f}) to Drive\")\n","\n","        artifact = wandb.Artifact(f'model-epoch-{epoch}', type='model')\n","        artifact.add_file(LOCAL_CHECKPOINT_PATH)\n","        wandb.log_artifact(artifact)\n","\n","    # Save Latest (Safety)\n","    torch.save({\n","        'epoch': epoch, 'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(), 'mAP': ap\n","    }, LOCAL_LATEST_PATH)\n","    shutil.copy(LOCAL_LATEST_PATH, DRIVE_LATEST_PATH) # Sync to Drive\n","    print(\"   ->  Saved Safety Backup to Drive\")\n","\n","wandb.finish()\n","print(\" Full Training Pipeline Completed Successfully.\")"]},{"cell_type":"code","source":[],"metadata":{"id":"o3y2szgCowkg"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNXn+kOci6ThO4eLfY7Vclq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}