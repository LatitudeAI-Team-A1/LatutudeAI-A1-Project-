{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPpeXlmXhY246r5gHVPKrtP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlrnWXW5R9e2","executionInfo":{"status":"ok","timestamp":1764215586608,"user_tz":300,"elapsed":287143,"user":{"displayName":"Joseph Boadi","userId":"06232502213247757960"}},"outputId":"2bbf19e6-b1f9-4a42-a1d1-aac39b200b61"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”Œ Mounting Google Drive...\n","Mounted at /content/drive\n","ğŸ“¦ Found backup zip. Unzipping to speed up process...\n","âœ… Unzipped backup.\n","ğŸš€ Scanning /content/drive/MyDrive/Latitude_AI_Team/data/bdd100k_segmentations/bdd100k_seg_maps_2/labels/val for full validation set...\n","ğŸ“‹ Found 1000 validation images.\n","âš™ï¸ Processing any missing files...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:14<00:00, 68.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","âœ… FULL VALIDATION SET READY.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# ==============================================================================\n","# CELL 1: VALIDATION DATA PREPARATION\n","# ==============================================================================\n","import os\n","import shutil\n","import torch\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","from scipy.ndimage import label as cc_label\n","from google.colab import drive\n","\n","# 1. MOUNT DRIVE\n","if not os.path.exists('/content/drive'):\n","    print(\"ğŸ”Œ Mounting Google Drive...\")\n","    drive.mount('/content/drive', force_remount=True)\n","\n","# 2. CONFIGURATION\n","DRIVE_ROOT = \"/content/drive/MyDrive/Latitude_AI_Team/data\"\n","VAL_MASK_DIR = f\"{DRIVE_ROOT}/bdd100k_segmentations/bdd100k_seg_maps_2/labels/val\"\n","VAL_IMG_DIR = f\"{DRIVE_ROOT}/bdd100k_images_10k/10k/val\"\n","ZIP_PATH = os.path.join(DRIVE_ROOT, \"bdd100k_fast_cache.zip\")\n","\n","# Local Dirs\n","DATA_ROOT = \"/content/data\"\n","SAVE_DIR_PT = os.path.join(DATA_ROOT, \"precomputed_masks\")\n","SAVE_DIR_IMG = os.path.join(DATA_ROOT, \"images/val\")\n","\n","os.makedirs(SAVE_DIR_PT, exist_ok=True)\n","os.makedirs(SAVE_DIR_IMG, exist_ok=True)\n","\n","# 3. RESTORE FROM BACKUP (If available)\n","if os.path.exists(ZIP_PATH):\n","    print(f\" Found backup zip. Unzipping to speed up process...\")\n","    try:\n","        shutil.unpack_archive(ZIP_PATH, DATA_ROOT)\n","        print(\" Unzipped backup.\")\n","    except:\n","        print(\" Zip failed (might be corrupt). Proceeding with generation.\")\n","\n","# 4. FILL MISSING VALIDATION DATA (Ensure we have all ~1000)\n","print(f\" Scanning {VAL_MASK_DIR} for full validation set...\")\n","all_files = sorted([f for f in os.listdir(VAL_MASK_DIR) if f.endswith('.png')])\n","print(f\" Found {len(all_files)} validation images.\")\n","\n","BDD_IDS = [6, 7, 11, 13, 12, 14, 15, 17, 18]\n","ID_TO_LABEL = {bdd_id: i+1 for i, bdd_id in enumerate(BDD_IDS)}\n","\n","print(\"âš™ï¸ Processing any missing files...\")\n","for mask_file in tqdm(all_files):\n","    try:\n","        basename = mask_file.replace(\"_train_id.png\", \"\")\n","        pt_path = os.path.join(SAVE_DIR_PT, basename + \".pt\")\n","\n","        # Check if we already have this file (from zip or previous run)\n","        # AND check if the image exists locally\n","        dst_img = os.path.join(SAVE_DIR_IMG, basename + \".jpg\")\n","        if os.path.exists(pt_path) and os.path.exists(dst_img):\n","            continue\n","\n","        # Generate .pt if missing\n","        mask_path = os.path.join(VAL_MASK_DIR, mask_file)\n","        mask_np = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.int32)\n","\n","        boxes, labels, final_masks = [], [], []\n","        for bdd_id in BDD_IDS:\n","            class_mask = (mask_np == bdd_id).astype(np.uint8)\n","            if class_mask.sum() < 10: continue\n","\n","            inst_map, ninst = cc_label(class_mask)\n","            for i in range(1, ninst+1):\n","                pos = np.where(inst_map == i)\n","                ymin, xmin = np.min(pos[0]), np.min(pos[1])\n","                ymax, xmax = np.max(pos[0]), np.max(pos[1])\n","                if (ymax-ymin)<5 or (xmax-xmin)<5: continue\n","\n","                boxes.append([xmin, ymin, xmax, ymax])\n","                labels.append(ID_TO_LABEL[bdd_id])\n","                final_masks.append((inst_map == i).astype(np.uint8))\n","\n","        if boxes:\n","            torch.save({\n","                \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n","                \"labels\": torch.tensor(labels, dtype=torch.int64),\n","                \"masks\": torch.tensor(np.array(final_masks), dtype=torch.uint8)\n","            }, pt_path)\n","\n","            # Copy Image\n","            src_img = os.path.join(VAL_IMG_DIR, basename + \".jpg\")\n","            if os.path.exists(src_img): shutil.copy(src_img, dst_img)\n","\n","    except Exception as e:\n","        pass\n","\n","print(\"\\nâœ… FULL VALIDATION SET READY.\")"]},{"cell_type":"code","source":["# ==============================================================================\n","# CELL 2: FINAL EVALUATION ON 1000 IMAGES\n","# ==============================================================================\n","!pip install torchmetrics -q\n","\n","import torch\n","import os\n","import torchvision\n","import torchvision.transforms as T\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","from torchmetrics.detection import MeanAveragePrecision\n","from tqdm import tqdm\n","\n","# 1. SETUP\n","DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n","print(f\" Evaluating on: {DEVICE}\")\n","\n","# Paths\n","PT_DIR = \"/content/data/precomputed_masks\"\n","VAL_IMG_DIR = \"/content/data/images/val\"\n","\n","# Checkpoint Search (Drive or Local)\n","CHECKPOINT_FILENAME = \"best_model_checkpoint_full_run.pth\"\n","DRIVE_MODELS_DIR = \"/content/drive/MyDrive/Latitude_AI_Team/models\"\n","DRIVE_PATH = os.path.join(DRIVE_MODELS_DIR, CHECKPOINT_FILENAME)\n","# Fallback if it was saved in root\n","LEGACY_PATH = \"/content/drive/MyDrive/Latitude_AI_Team/best_model_checkpoint_full_run.pth\"\n","\n","MODEL_PATH = None\n","if os.path.exists(DRIVE_PATH): MODEL_PATH = DRIVE_PATH\n","elif os.path.exists(LEGACY_PATH): MODEL_PATH = LEGACY_PATH\n","\n","if not MODEL_PATH:\n","    raise FileNotFoundError(\"âŒ Could not find checkpoint file in Drive!\")\n","\n","# 2. DATASET CLASS\n","class BDDPrecomputedDataset(Dataset):\n","    def __init__(self, img_dir, pt_dir, basenames):\n","        self.img_dir = img_dir; self.pt_dir = pt_dir; self.basenames = basenames\n","    def __len__(self): return len(self.basenames)\n","    def __getitem__(self, idx):\n","        basename = self.basenames[idx]\n","        img = Image.open(os.path.join(self.img_dir, basename + \".jpg\")).convert(\"RGB\")\n","        data = torch.load(os.path.join(self.pt_dir, basename + \".pt\"))\n","        target = {\"boxes\": data[\"boxes\"], \"labels\": data[\"labels\"], \"masks\": data[\"masks\"], \"image_id\": torch.tensor([idx])}\n","        return T.ToTensor()(img), target\n","\n","def collate_fn(batch): return tuple(zip(*batch))\n","\n","# 3. LOAD DATA\n","# Get all validation files that exist locally\n","val_files = sorted([f.replace('.jpg', '') for f in os.listdir(VAL_IMG_DIR)\n","                    if os.path.exists(os.path.join(PT_DIR, f.replace('.jpg', '.pt')))])\n","\n","print(f\"Evaluating on {len(val_files)} images.\")\n","\n","val_loader = DataLoader(\n","    BDDPrecomputedDataset(VAL_IMG_DIR, PT_DIR, val_files),\n","    batch_size=1, shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True\n",")\n","\n","# 4. LOAD MODEL\n","BDD_IDS = [6, 7, 11, 13, 12, 14, 15, 17, 18]\n","model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=None) # No pre-train needed, we load ours\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 1 + len(BDD_IDS))\n","in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, 1 + len(BDD_IDS))\n","\n","print(f\" Loading weights from: {MODEL_PATH}\")\n","ckpt = torch.load(MODEL_PATH, map_location=DEVICE)\n","model.load_state_dict(ckpt['model_state_dict'])\n","model.to(DEVICE)\n","model.eval()\n","\n","# 5. RUN METRICS\n","print(\" Starting Inference Loop...\")\n","metric = MeanAveragePrecision(box_format=\"xyxy\", iou_type=\"segm\").to(DEVICE)\n","\n","with torch.no_grad():\n","    for i, (images, targets) in tqdm(enumerate(val_loader), total=len(val_loader)):\n","        images = [img.to(DEVICE) for img in images]\n","        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n","\n","        outputs = model(images)\n","        processed = []\n","        for pred in outputs:\n","            if 'masks' in pred: pred['masks'] = (pred['masks'] > 0.5).squeeze(1).to(torch.uint8)\n","            processed.append(pred)\n","        metric.update(processed, targets)\n","\n","print(\"\\nComputing Final Scores...\")\n","res = metric.compute()\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\" OFFICIAL VALIDATION RESULTS\")\n","print(\"=\"*50)\n","print(f\"AP @[.50:.95]: {res['map'].item():.4f}\")\n","print(f\"AP @ .50:      {res['map_50'].item():.4f}\")\n","print(f\"AP @ .75:      {res['map_75'].item():.4f}\")\n","print(f\"AP (Small):    {res['map_small'].item():.4f}\")\n","print(\"=\"*50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1PXYAXIaSKYC","executionInfo":{"status":"ok","timestamp":1764215853335,"user_tz":300,"elapsed":260071,"user":{"displayName":"Joseph Boadi","userId":"06232502213247757960"}},"outputId":"2b722bff-862b-4557-ddb8-dc7a9eb10f5f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.9/983.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hğŸš€ Evaluating on: cuda\n","ğŸ“Š Evaluating on 988 images.\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 227MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["ğŸ”„ Loading weights from: /content/drive/MyDrive/Latitude_AI_Team/models/best_model_checkpoint_full_run.pth\n","ğŸš€ Starting Inference Loop...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 988/988 [03:51<00:00,  4.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Computing Final Scores...\n","\n","==================================================\n","ğŸ† OFFICIAL VALIDATION RESULTS\n","==================================================\n","AP @[.50:.95]: 0.2702\n","AP @ .50:      0.4705\n","AP @ .75:      0.2653\n","AP (Small):    0.1305\n","==================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"WBASgTuKXshm"},"execution_count":null,"outputs":[]}]}